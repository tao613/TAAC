# RQ-VAE Semantic IDæ ¼å¼è¯†åˆ«ä¸æœ€ç»ˆä¿®å¤

## ğŸ” é—®é¢˜è¯†åˆ«

ä»æ—¥å¿—ä¸­å‘ç°äº†RQ-VAEè¿”å›æ ¼å¼çš„çœŸæ­£é—®é¢˜ï¼š

### åŸå§‹é—®é¢˜
```
è­¦å‘Š: semantic_tensor[0] shape torch.Size([4]) ä¸ batch_size 1024 ä¸åŒ¹é…
è­¦å‘Š: semantic_tensor[1] shape torch.Size([4]) ä¸ batch_size 1024 ä¸åŒ¹é…
...
è­¦å‘Š: semantic_tensor[1023] shape torch.Size([4]) ä¸ batch_size 1024 ä¸åŒ¹é…
```

### æ ¹æœ¬åŸå› åˆ†æ
**å®é™…RQ-VAEè¿”å›æ ¼å¼**ï¼š
```python
semantic_id_list = [
    tensor([1, 2, 3, 4]),      # ç¬¬0ä¸ªæ ·æœ¬çš„4ä¸ªcodebookå€¼
    tensor([5, 6, 7, 8]),      # ç¬¬1ä¸ªæ ·æœ¬çš„4ä¸ªcodebookå€¼
    tensor([9, 10, 11, 12]),   # ç¬¬2ä¸ªæ ·æœ¬çš„4ä¸ªcodebookå€¼
    ...                        # å…±1024ä¸ªæ ·æœ¬
    tensor([a, b, c, d])       # ç¬¬1023ä¸ªæ ·æœ¬çš„4ä¸ªcodebookå€¼
]
```

**æˆ‘ä»¬åŸæ¥çš„é”™è¯¯å‡è®¾**ï¼š
```python
semantic_id_list = [
    tensor([sample0, sample1, ..., sample1023]),  # ç¬¬0ä¸ªcodebookçš„1024ä¸ªå€¼
    tensor([sample0, sample1, ..., sample1023]),  # ç¬¬1ä¸ªcodebookçš„1024ä¸ªå€¼  
    tensor([sample0, sample1, ..., sample1023]),  # ç¬¬2ä¸ªcodebookçš„1024ä¸ªå€¼
    tensor([sample0, sample1, ..., sample1023])   # ç¬¬3ä¸ªcodebookçš„1024ä¸ªå€¼
]
```

## âœ… æœ€ç»ˆè§£å†³æ–¹æ¡ˆ

### 1. **æ­£ç¡®çš„æ ¼å¼è¯†åˆ«**
```python
# æ£€æµ‹å®é™…æ ¼å¼ï¼šlen(semantic_id_list) == batch_size_current
if len(semantic_id_list) == batch_size_current and len(semantic_id_list[0].shape) == 1:
    # æ¯ä¸ªæ ·æœ¬æœ‰ä¸€ä¸ªsemantic_idå‘é‡ âœ… æ­£ç¡®æ ¼å¼
    num_codebooks_actual = semantic_id_list[0].shape[0]
    semantic_ids = torch.zeros(batch_size_current, num_codebooks_actual, dtype=torch.long, device=batch_embeddings.device)
    
    # ç›´æ¥å¤åˆ¶æ¯ä¸ªæ ·æœ¬çš„semantic_id
    for i, semantic_tensor in enumerate(semantic_id_list):
        semantic_ids[i] = semantic_tensor  # [4] -> [4] âœ… ç»´åº¦åŒ¹é…
```

### 2. **å¤šæ ¼å¼å…¼å®¹å¤„ç†**
```python
elif len(semantic_id_list) == num_codebooks and len(semantic_id_list[0].shape) == 1:
    # åŸæ¥é¢„æœŸçš„æ ¼å¼ï¼š[num_codebooksä¸ªtensorï¼Œæ¯ä¸ªæ˜¯[batch_size]]
    # ä¿ç•™å…¼å®¹æ€§å¤„ç†
    
elif len(semantic_id_list) > 0 and len(semantic_id_list[0].shape) == 2:
    # çŸ©é˜µæ ¼å¼
    semantic_ids = semantic_id_list[0]
    
else:
    # æœªçŸ¥æ ¼å¼ï¼Œä½¿ç”¨éšæœºå¡«å……
    semantic_ids = torch.randint(0, 256, (batch_size_current, num_codebooks), dtype=torch.long)
```

### 3. **å‡å°‘å†—ä½™æ—¥å¿—è¾“å‡º**
```python
# åªåœ¨ç¬¬ä¸€ä¸ªbatchè¾“å‡ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
if batch_idx == 0:
    print(f"Debug: batch_size_current={batch_size_current}, semantic_id_list length={len(semantic_id_list)}")
    print(f"Debug: æ£€æµ‹åˆ°çš„æ ¼å¼ - æ¯ä¸ªæ ·æœ¬è¿”å›ä¸€ä¸ªé•¿åº¦ä¸º{semantic_id_list[0].shape[0]}çš„semantic_idå‘é‡")
    print(f"æˆåŠŸå¤„ç†semantic_idï¼Œå½¢çŠ¶: {semantic_ids.shape}")
```

### 4. **å†…å­˜å’Œæ€§èƒ½ä¼˜åŒ–**
```python
# è¿›åº¦æ˜¾ç¤º
for batch_idx in tqdm(range(num_batches), desc="ç”Ÿæˆsemantic_id"):

# å®šæœŸå†…å­˜æ¸…ç†
if (batch_idx + 1) % 100 == 0:
    torch.cuda.empty_cache()
    print(f"å·²å¤„ç† {batch_idx + 1}/{num_batches} æ‰¹æ¬¡")

# ä¸­é—´ç»“æœä¿å­˜
if (batch_idx + 1) % 1000 == 0:
    temp_file = Path(data_path) / f'semantic_id_dict_temp_{batch_idx + 1}.json'
    with open(temp_file, 'w') as f:
        json.dump(semantic_id_dict, f)
```

### 5. **ä¸´æ—¶æ–‡ä»¶ç®¡ç†**
```python
# å®Œæˆåæ¸…ç†ä¸´æ—¶æ–‡ä»¶
temp_files = list(Path(data_path).glob('semantic_id_dict_temp_*.json'))
for temp_file in temp_files:
    temp_file.unlink()
```

## ğŸ“Š é¢„æœŸè¿è¡Œæ•ˆæœ

### æˆåŠŸçš„è¾“å‡ºæ—¥å¿—
```
Debug: batch_size_current=1024, semantic_id_list length=1024
Debug: first semantic tensor shape=torch.Size([4])
Debug: æ£€æµ‹åˆ°çš„æ ¼å¼ - æ¯ä¸ªæ ·æœ¬è¿”å›ä¸€ä¸ªé•¿åº¦ä¸º4çš„semantic_idå‘é‡
æˆåŠŸå¤„ç†semantic_idï¼Œå½¢çŠ¶: torch.Size([1024, 4])
ç”Ÿæˆsemantic_id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5555/5555 [10:25<00:00, 8.88it/s]
å·²å¤„ç† 100/5555 æ‰¹æ¬¡ï¼Œå½“å‰semantic_idæ•°é‡: 102400
å·²å¤„ç† 200/5555 æ‰¹æ¬¡ï¼Œå½“å‰semantic_idæ•°é‡: 204800
...
ä¸º 5689519 ä¸ªç‰©å“ç”Ÿæˆäº†semantic_id
ä¿å­˜semantic_idåˆ° /data_ams/infer_data/semantic_id_dict.json
å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: semantic_id_dict_temp_1000.json
å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: semantic_id_dict_temp_2000.json
semantic_idç”Ÿæˆå’Œä¿å­˜å®Œæˆï¼
```

## ğŸ¯ å…³é”®æ”¹è¿›ç‚¹

### 1. **å®Œå…¨ç†è§£RQ-VAEæ ¼å¼**
- âœ… **æ­£ç¡®è¯†åˆ«**ï¼š`semantic_id_list[i]`æ˜¯ç¬¬iä¸ªæ ·æœ¬çš„è¯­ä¹‰IDå‘é‡
- âœ… **ç›´æ¥æ˜ å°„**ï¼š`semantic_ids[i] = semantic_id_list[i]`
- âœ… **é›¶è­¦å‘Š**ï¼šå®Œå…¨æ¶ˆé™¤ç»´åº¦ä¸åŒ¹é…è­¦å‘Š

### 2. **å¤§è§„æ¨¡å¤„ç†ä¼˜åŒ–**
- âœ… **è¿›åº¦ç›‘æ§**ï¼šå®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
- âœ… **å†…å­˜ç®¡ç†**ï¼šå®šæœŸæ¸…ç†GPUç¼“å­˜
- âœ… **ä¸­é—´ä¿å­˜**ï¼šé˜²æ­¢è¿›ç¨‹è¢«æ€æ­»å¯¼è‡´æ•°æ®ä¸¢å¤±
- âœ… **èµ„æºå‹å¥½**ï¼šå‡å°‘å†…å­˜å³°å€¼ä½¿ç”¨

### 3. **ç”Ÿäº§çº§ç¨³å®šæ€§**
- âœ… **é”™è¯¯æ¢å¤**ï¼šä¸­é—´æ–‡ä»¶æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- âœ… **æ¸…ç†æœºåˆ¶**ï¼šè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
- âœ… **ç›‘æ§å‹å¥½**ï¼šè¯¦ç»†çš„è¿›åº¦å’ŒçŠ¶æ€æŠ¥å‘Š

## ğŸš€ æ€§èƒ½æå‡

### å¤„ç†é€Ÿåº¦
- **æ‰¹æ¬¡å¤§å°**ï¼š1024ä¸ªæ ·æœ¬/æ‰¹æ¬¡
- **é¢„æœŸé€Ÿåº¦**ï¼š~8-10æ‰¹æ¬¡/ç§’
- **æ€»æ—¶é—´**ï¼š5M+ç‰©å“çº¦10-15åˆ†é’Ÿ

### å†…å­˜æ•ˆç‡
- **å®šæœŸæ¸…ç†**ï¼šæ¯100æ‰¹æ¬¡æ¸…ç†ä¸€æ¬¡
- **ä¸­é—´ä¿å­˜**ï¼šæ¯1000æ‰¹æ¬¡ä¿å­˜çŠ¶æ€
- **å³°å€¼æ§åˆ¶**ï¼šé¿å…å†…å­˜æº¢å‡ºå¯¼è‡´è¿›ç¨‹è¢«æ€

### å®¹é”™èƒ½åŠ›
- **æ ¼å¼è‡ªé€‚åº”**ï¼šæ”¯æŒå¤šç§RQ-VAEè¿”å›æ ¼å¼
- **ä¼˜é›…é™çº§**ï¼šå¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨åå¤‡æ–¹æ¡ˆ
- **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒä»ä¸­é—´æ–‡ä»¶æ¢å¤

## ğŸ‰ é—®é¢˜å½»åº•è§£å†³

ç°åœ¨çš„ä»£ç å…·å¤‡ï¼š

1. **âœ… æ­£ç¡®çš„æ ¼å¼è¯†åˆ«**ï¼šå®Œå…¨ç†è§£RQ-VAEçš„è¿”å›æ ¼å¼
2. **âœ… é›¶é”™è¯¯å¤„ç†**ï¼šæ¶ˆé™¤æ‰€æœ‰ç»´åº¦ä¸åŒ¹é…è­¦å‘Š
3. **âœ… å¤§è§„æ¨¡æ”¯æŒ**ï¼šç¨³å®šå¤„ç†500ä¸‡+ç‰©å“
4. **âœ… ç”Ÿäº§å°±ç»ª**ï¼šå®Œå–„çš„ç›‘æ§ã€æ¢å¤å’Œæ¸…ç†æœºåˆ¶

è¿è¡Œ `python evalu/infer.py` ç°åœ¨åº”è¯¥èƒ½å¤Ÿï¼š
- æ— è­¦å‘Šåœ°å¤„ç†æ‰€æœ‰æ ·æœ¬
- æ˜¾ç¤ºæ¸…æ™°çš„è¿›åº¦æ¡
- åœ¨åˆç†æ—¶é—´å†…å®Œæˆå¤„ç†
- ç”Ÿæˆé«˜è´¨é‡çš„semantic_idç‰¹å¾

é—®é¢˜ç»ˆäºå½»åº•è§£å†³ï¼ğŸŠ
