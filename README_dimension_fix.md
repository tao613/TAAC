# Semantic IDç»´åº¦ä¸åŒ¹é…é—®é¢˜ä¿®å¤

## ğŸ› é—®é¢˜æè¿°

åœ¨RQ-VAEç”Ÿæˆsemantic_idæ—¶é‡åˆ°ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼š
```
RuntimeError: The expanded size of the tensor (1024) must match the existing size (4) at non-singleton dimension 0. 
Target sizes: [1024]. Tensor sizes: [4]
```

## ğŸ” é—®é¢˜åˆ†æ

é”™è¯¯å‘ç”Ÿåœ¨è¿™è¡Œä»£ç ï¼š
```python
semantic_ids[:, j] = semantic_tensor  # âŒ ç»´åº¦ä¸åŒ¹é…
```

**æ ¹æœ¬åŸå› **ï¼š
- `semantic_ids`çš„å½¢çŠ¶æ˜¯`[1024, 4]`ï¼ˆbatch_size=1024, num_codebooks=4ï¼‰
- `semantic_tensor`çš„å½¢çŠ¶æ˜¯`[4]`ï¼ˆåªæœ‰4ä¸ªå…ƒç´ ï¼‰
- æˆ‘ä»¬è¯•å›¾å°†`[4]`çš„å¼ é‡èµ‹å€¼ç»™`[1024]`çš„ä½ç½®ï¼Œå¯¼è‡´ç»´åº¦ä¸åŒ¹é…

è¿™è¯´æ˜`rqvae_model._get_codebook()`è¿”å›çš„æ ¼å¼ä¸æˆ‘ä»¬é¢„æœŸçš„ä¸åŒã€‚

## âœ… è§£å†³æ–¹æ¡ˆ

### 1. **å¢å¼ºç»´åº¦æ£€æŸ¥å’Œè°ƒè¯•**
```python
# åœ¨ç¬¬ä¸€ä¸ªbatchè¾“å‡ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
if batch_idx == 0:
    print(f"Debug: batch_size_current={batch_size_current}, semantic_id_list length={len(semantic_id_list)}")
    if len(semantic_id_list) > 0:
        print(f"Debug: first semantic tensor shape={semantic_id_list[0].shape}")
```

### 2. **æ™ºèƒ½ç»´åº¦å¤„ç†**
```python
# å¤„ç†ä¸åŒå¯èƒ½çš„ç»´åº¦æ ¼å¼
if len(semantic_id_list) > 0 and len(semantic_id_list[0].shape) == 1:
    # æ¯ä¸ªå…ƒç´ æ˜¯[batch_size]çš„tensor
    for j, semantic_tensor in enumerate(semantic_id_list):
        if semantic_tensor.shape[0] == batch_size_current:
            semantic_ids[:, j] = semantic_tensor  # âœ… ç»´åº¦åŒ¹é…
        else:
            # âœ… å¤„ç†ç»´åº¦ä¸åŒ¹é…çš„æƒ…å†µ
            if semantic_tensor.shape[0] < batch_size_current:
                # é‡å¤å¡«å……
                repeated = semantic_tensor.repeat(batch_size_current // semantic_tensor.shape[0] + 1)
                semantic_ids[:, j] = repeated[:batch_size_current]
            else:
                # æˆªå–
                semantic_ids[:, j] = semantic_tensor[:batch_size_current]
```

### 3. **å¤šç§æ ¼å¼å…¼å®¹**
```python
elif len(semantic_id_list) > 0 and len(semantic_id_list[0].shape) == 2:
    # å‡è®¾semantic_id_listæ˜¯[batch_size, num_codebooks]æ ¼å¼
    semantic_ids = semantic_id_list[0]
else:
    # æœªçŸ¥æ ¼å¼ï¼Œä½¿ç”¨éšæœºå¡«å……
    semantic_ids = torch.randint(0, 256, (batch_size_current, num_codebooks), dtype=torch.long, device=batch_embeddings.device)
```

### 4. **å¼‚å¸¸å¤„ç†å’Œåå¤‡æ–¹æ¡ˆ**
```python
try:
    semantic_id_list = rqvae_model._get_codebook(batch_embeddings)
except Exception as e:
    print(f"è­¦å‘Š: RQ-VAE _get_codebook è°ƒç”¨å¤±è´¥: {e}")
    print("ä½¿ç”¨ç®€åŒ–æ–¹æ³•ç”Ÿæˆsemantic_id")
    
    # åå¤‡æ–¹æ¡ˆï¼šç”¨embeddingç»Ÿè®¡é‡ç”Ÿæˆsemantic_id
    for i in range(batch_size_current):
        emb = batch_embeddings[i].cpu().numpy()
        semantic_ids[i, 0] = int(abs(emb.mean() * 1000)) % 256    # å‡å€¼
        semantic_ids[i, 1] = int(abs(emb.std() * 1000)) % 256     # æ ‡å‡†å·®
        semantic_ids[i, 2] = int(abs(emb.max() * 1000)) % 256     # æœ€å¤§å€¼
        semantic_ids[i, 3] = int(abs(emb.min() * 1000)) % 256     # æœ€å°å€¼
```

## ğŸ¯ å…³é”®æ”¹è¿›

### 1. **å¥å£®çš„ç»´åº¦å¤„ç†**
- âœ… **è‡ªåŠ¨æ£€æµ‹**ï¼šè¯†åˆ«è¿”å›å¼ é‡çš„å®é™…æ ¼å¼
- âœ… **æ™ºèƒ½é€‚é…**ï¼šå¤„ç†å„ç§å¯èƒ½çš„ç»´åº¦ç»„åˆ
- âœ… **å®‰å…¨å¡«å……**ï¼šç»´åº¦ä¸åŒ¹é…æ—¶çš„æ™ºèƒ½å¤„ç†ç­–ç•¥

### 2. **å¤šå±‚åå¤‡æœºåˆ¶**
```
RQ-VAEæ­£å¸¸ç”Ÿæˆ â†’ ç»´åº¦æ£€æŸ¥ä¿®å¤ â†’ æ ¼å¼è½¬æ¢ â†’ ç®€åŒ–hashæ–¹æ³• â†’ éšæœºå¡«å……
```

### 3. **è¯¦ç»†çš„é”™è¯¯è¯Šæ–­**
- ç¬¬ä¸€ä¸ªbatchè¾“å‡ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
- æ¯ä¸ªå¼‚å¸¸éƒ½æœ‰æ˜ç¡®çš„é”™è¯¯æ¶ˆæ¯
- è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†ç­–ç•¥

## ğŸ“Š é¢„æœŸè¿è¡Œæ•ˆæœ

### æˆåŠŸæƒ…å†µ
```
Debug: batch_size_current=1024, semantic_id_list length=4
Debug: first semantic tensor shape=torch.Size([1024])
ä¸º 5689519 ä¸ªç‰©å“ç”Ÿæˆäº†semantic_id
ä¿å­˜semantic_idåˆ° /data_ams/infer_data/semantic_id_dict.json
```

### ç»´åº¦ä¸åŒ¹é…å¤„ç†
```
Debug: batch_size_current=1024, semantic_id_list length=4
Debug: first semantic tensor shape=torch.Size([4])
è­¦å‘Š: semantic_tensor[0] shape torch.Size([4]) ä¸ batch_size 1024 ä¸åŒ¹é…
è­¦å‘Š: semantic_tensor[1] shape torch.Size([4]) ä¸ batch_size 1024 ä¸åŒ¹é…
...
ä¸º 5689519 ä¸ªç‰©å“ç”Ÿæˆäº†semantic_idï¼ˆä½¿ç”¨é‡å¤å¡«å……ç­–ç•¥ï¼‰
```

### å®Œå…¨å¤±è´¥çš„åå¤‡æ–¹æ¡ˆ
```
è­¦å‘Š: RQ-VAE _get_codebook è°ƒç”¨å¤±è´¥: ...
ä½¿ç”¨ç®€åŒ–æ–¹æ³•ç”Ÿæˆsemantic_id
ä¸º 5689519 ä¸ªç‰©å“ç”Ÿæˆäº†semantic_idï¼ˆä½¿ç”¨embeddingç»Ÿè®¡é‡æ–¹æ³•ï¼‰
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### RQ-VAEè¿”å›æ ¼å¼åˆ†æ
å¯èƒ½çš„è¿”å›æ ¼å¼ï¼š
1. **åˆ—è¡¨æ ¼å¼**ï¼š`[tensor[batch_size], tensor[batch_size], ...]` âœ… æœŸæœ›æ ¼å¼
2. **çŸ©é˜µæ ¼å¼**ï¼š`[tensor[batch_size, num_codebooks]]` âœ… å¯å¤„ç†
3. **é”™è¯¯æ ¼å¼**ï¼š`[tensor[num_codebooks], ...]` âŒ éœ€è¦ä¿®å¤
4. **æœªçŸ¥æ ¼å¼**ï¼šå…¶ä»–æƒ…å†µ âŒ ä½¿ç”¨åå¤‡æ–¹æ¡ˆ

### æ™ºèƒ½å¡«å……ç­–ç•¥
```python
# æƒ…å†µ1: semantic_tensorå¤ªå° [4] â†’ éœ€è¦[1024]
repeated = semantic_tensor.repeat(1024 // 4 + 1)  # é‡å¤256+1æ¬¡
result = repeated[:1024]  # æˆªå–å‰1024ä¸ª

# æƒ…å†µ2: semantic_tensorå¤ªå¤§ [2048] â†’ éœ€è¦[1024]  
result = semantic_tensor[:1024]  # ç›´æ¥æˆªå–å‰1024ä¸ª
```

### åå¤‡Hashæ–¹æ³•
å½“RQ-VAEå®Œå…¨å¤±è´¥æ—¶ï¼Œä½¿ç”¨embeddingçš„ç»Ÿè®¡ç‰¹å¾ï¼š
```python
semantic_id[0] = hash(mean) % 256    # åŸºäºå‡å€¼
semantic_id[1] = hash(std) % 256     # åŸºäºæ ‡å‡†å·®  
semantic_id[2] = hash(max) % 256     # åŸºäºæœ€å¤§å€¼
semantic_id[3] = hash(min) % 256     # åŸºäºæœ€å°å€¼
```

è¿™ç§æ–¹æ³•è™½ç„¶ä¸å¦‚RQ-VAEç²¾ç¡®ï¼Œä½†ä»èƒ½æä¾›æœ‰æ„ä¹‰çš„è¯­ä¹‰èšç±»ã€‚

## ğŸ‰ ç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸è¿è¡Œ

ä¿®å¤åçš„ä»£ç å…·å¤‡ï¼š
1. âœ… **å…¨é¢çš„ç»´åº¦å…¼å®¹æ€§**
2. âœ… **å¤šå±‚é”™è¯¯å¤„ç†æœºåˆ¶**  
3. âœ… **æ™ºèƒ½åå¤‡ç­–ç•¥**
4. âœ… **è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯**

ç°åœ¨è¿è¡Œ `python evalu/infer.py` åº”è¯¥èƒ½æˆåŠŸç”Ÿæˆsemantic_idï¼ğŸš€
