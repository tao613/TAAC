# 推荐模型优化方案 (2024-08-07)

本方案旨在通过对特征工程、模型结构、训练策略和推理架构的系统性优化，显著提升现有推荐模型的预测准确率。

---

### 优化方案总览

| 优化阶段 | 核心任务 | 具体措施 | 预计影响 | 实施复杂度 |
| :--- | :--- | :--- | :--- | :--- |
| **第一阶段** | **基础强化：稳定训练与特征增强** | 1. **引入时间特征** (`time_of_day`, `day_of_week`, `time_delta`)<br>2. **启用 Pre-LayerNorm** (`--norm_first`)<br>3. **增加学习率调度器** (Warmup + Cosine Decay)<br>4. **实现早停机制** (Early Stopping) | 高 | 中 |
| **第二阶段** | **高级训练：改进损失函数与负采样** | 1. **升级负采样策略** (从随机采样到In-batch Negatives)<br>2. **优化损失函数** (从 Pairwise BCE Loss 到 Listwise InfoNCE Loss) | 高 | 中 |
| **第三阶段** | **架构升级：引入两阶段排序** | 1. **改造召回模型**：生成更大候选集 (e.g., Top 200)<br>2. **构建精排模型**：对候选集进行精准排序，可引入复杂交叉特征 | 极高 | 高 |

---

### 方案详解

#### 第一阶段：基础强化 (High Impact, Medium Complexity)

这是性价比最高的优化，改动相对较小，但通常能带来显著的效果提升。

1.  **引入时间特征 (Feature Engineering)**
    *   **问题**: 当前模型完全忽略了 `timestamp` 字段，丢失了宝贵的用户行为模式信息。
    *   **方案**: 在 `dataset.py` 中，从 `timestamp` 派生出三个新特征：
        *   `time_of_day`: 一天中的小时 (0-23)，用于捕捉用户的日活跃规律。
        *   `day_of_week`: 一周中的天 (0-6)，用于捕捉周内/周末的行为差异。
        *   `time_delta`: 与序列中上一个行为的时间间隔（秒），可以帮助模型识别用户**会话（Session）**，对于判断兴趣的连续性至关重要。
    *   **收益**: 让模型理解用户的作息习惯、会话状态和兴趣衰减，极大增强序列建模能力。

2.  **启用 Pre-LayerNorm (Model Architecture)**
    *   **问题**: 原始的 Post-LayerNorm Transformer 在层数加深时可能出现训练不稳定的问题。
    *   **方案**: 默认启用 `--norm_first` 参数。这将激活 Pre-LayerNorm 结构 (`LayerNorm -> Attention -> Residual`)，这种结构被证明训练更稳定，收敛更快。

3.  **增加学习率调度器 (Training Strategy)**
    *   **问题**: 使用固定的学习率 (`lr`) 限制了模型收敛到最优点的能力。
    *   **方案**: 在 `main.py` 中引入带有 **Warmup** 的 **Cosine Annealing** 学习率调度器。
        *   **Warmup**: 在训练初期使用一个较小的学习率，帮助模型稳定启动。
        *   **Cosine Annealing**: 之后学习率会像余弦函数一样平滑下降，有助于模型在训练后期更精细地收敛。
    *   **收益**: 加速收敛，并有助于模型跳出局部最优，找到更好的解。

4.  **实现早停机制 (Early Stopping)**
    *   **问题**: 训练固定的 epoch 数量容易导致模型欠拟合或过拟合。
    *   **方案**: 在 `main.py` 中增加 Early Stopping 机制。我们会监控验证集上的损失 (`validation loss`)，如果连续多个 epoch 没有改善，就提前终止训练，并保存迄今为止效果最好的模型。
    *   **收益**: 防止过拟合，自动找到最佳训练周期，并节省计算资源。

---

#### 第二阶段：高级训练 (High Impact, Medium Complexity)

在完成第一阶段的基础上，这些改动能进一步压榨模型性能，让模型学会更精细的排序。

1.  **升级负采样策略 (In-batch Negatives)**
    *   **问题**: 当前的随机负采样过于简单，模型很容易区分正负样本，不利于学习细粒度的偏好。
    *   **方案**: 切换到 **In-batch Negatives** 策略。对于序列中的每个正样本，我们将同一个 batch 内的其他所有用户的正样本作为它的负样本。
    *   **收益**:
        *   **高效**: 无需额外的采样开销。
        *   **有效**: 这些负样本通常比随机样本更“难”，因为它们也是被真实用户点击过的物品，能迫使模型学习更具区分度的用户和物品表示。

2.  **优化损失函数 (InfoNCE Loss)**
    *   **问题**: Pairwise BCE Loss 独立地看待每个负样本，没有考虑负样本之间的关系。
    *   **方案**: 将损失函数从 BCE Loss 升级为 **InfoNCE Loss**。该损失函数将问题看作一个多分类任务：模型需要从一个正样本和多个负样本中准确地识别出那个正样本。它与 In-batch Negatives 策略是天作之合。
    *   **收益**: InfoNCE 是一种对比学习损失，它能更好地构建 embedding 空间，使得相似的用户/物品在空间中更接近，不相似的则更疏远，从而提升召回和排序的准确性。

---

#### 第三阶段：架构升级 (Highest Impact, High Complexity)

这是工业界推荐系统最标准的架构，效果最好，但需要对代码进行较大规模的重构。

1.  **引入两阶段排序架构 (Recall -> Re-rank)**
    *   **问题**: 单一模型同时负责从百万物品库中“捞出”候选（召回）和对这些候选进行“排序”，难以兼顾效率和精度。
    *   **方案**:
        *   **召回阶段**: 使用我们优化后的模型，通过ANN快速从全量物品库中召回一个更大的候选集（例如 Top 200）。此阶段追求“快”和“全”。
        *   **精排阶段**: 设计一个**新的、更复杂**的精排模型，它只对这 200 个候选进行打分。由于处理的物品数量少，精排模型可以使用更强大的特征，例如：
            *   **用户与候选物品的交叉特征**：`user_age` x `item_category` 等。
            *   **实时的上下文特征**。
    *   **收益**: 这是业界公认最有效的提升推荐效果的架构。召回保证不漏掉好结果，精排保证结果排序的精准性，最终大幅提升准确率。
